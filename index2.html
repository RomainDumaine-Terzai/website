<!DOCTYPE html>
<html class="not-ie no-js" lang="en" xmlns="http://www.w3.org/1999/html" xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <link rel="apple-touch-icon" href="images/apple-touch-icon.png"/>
    <link rel="apple-touch-startup-image" href="images/startup.png" media="screen and (max-device-width: 320px)">
    <link rel="apple-touch-startup-image" href="images/startup_402x.png" media="(max-device-width: 480px) and (-webkit-min-device-pixel-ratio: 2)">

    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="apple-mobile-web-app-capable" content="yes" />

      <title>Romain Dumaine: Kinect Sound Effect : Interactive Glove : Portfolio : Blog</title>

		<meta name="description" content="Personal portfolio of Romain Dumaine" />
		<meta name="author" content="Romain Dumaine" />
		<meta name="robots" content="index, follow" />
        <meta name="Keywords" content="Romain Dumaine, Kinect DJ Maxx, Kinect, Max/Msp, interactive glove, max for live, story of a shaped sound, interactivity, sonic artist, sound design" />

    <!--[if !lte IE 6]><!-->
    <link rel="stylesheet" href="css/style.css" media="screen"/>
    <link rel="stylesheet" href="flexslider/flexslider.css" media="screen"/>
    <link rel="stylesheet" href="css/promptumenu.css" media="screen"/>

    <link rel="stylesheet"
          href="../../../fonts.googleapis.com/css@family=Open+Sans_3A400,600,300,800,700,400italic_7CPT+Serif_3A400,400italic"/>

    <link rel="icon"
          type="image/png"
          href="images/apple-touch-icon.png">
		
	<script type="text/javascript">
				  var _gaq = _gaq || [];
				  _gaq.push(['_setAccount', 'UA-20563216-2']);
				  _gaq.push(['_trackPageview']);
				
				  (function() {
				    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
				    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
				    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
				  })();
	</script>

    <script src="js/modernizr.custom.js"></script>
</head>
<body>

<header id="header">
    <div class="container clearfix">
        <a href="../index2.html" title="Logo" id="logo">
            <img src="img/logo2.png" alt="Logo"/>
        </a>
</header>


<section class="fullContainer">
    <div id="flex-slider" class="container clearfix big-slider">
        <ul class="slides">
            <li>
                <article class="slide-article">
                    <div class="slide-details">
                        <h1>About</h1>
                        <h2>Romain Dumaine</h2>

                        <p>Romain Dumaine is French <span class="strong">composer</span> and <span class="strong">sonic artist </span> based in Belfast. His academic background had led him to study in <a href="http://iut-geii.org" target="_blank">France</a>, <a href="http://www.gmit.ie/engineering/electronic/level-8-programmes/beng-cee-hons.html" target="_blank">Ireland</a>, <a href="http://www.glyndwr.ac.uk/en/Undergraduatecourses/ElectricalandElectronicEngineering" target="_blank">Wales</a>, <a href="http://www.abertay.ac.uk/studying/find/ug/sound/" target="_blank">Scotland</a> and finally <a href="http://www.qub.ac.uk/schools/SchoolofCreativeArts/MusicSonicArts/ProspectiveStudents/TaughtPostgraduateProgrammes/MAinSonicArts/" target="_blank">Northern Ireland</a>.</p>
      <p> His knowledge of electronics and his attraction to Sonic Art motivated him to progressively build different <span class="strong">musical interfaces and instruments</span>.</p>
      <p> His inspiration focuses on <span class="strong"> body musical interaction</span>. Romain Dumaine is an MA Sonic Arts student at <a href="http://www.qub.ac.uk/schools/SchoolofCreativeArts/MusicSonicArts/ProspectiveStudents/TaughtPostgraduateProgrammes/MAinSonicArts/" target="_blank">SARC</a> who plans to continue experiment in this field with a focus on different approaches to enhance the <span class="strong">exchange between performer and audience</span>.</p>
                       
                            <li><a href="http://facebook.com/Terzai" target="_blank">FACEBOOK</a>        </li>
                            <li><a href="http://twitter.com/RoDumaine" target="_blank">TWITTER</a>       </li>
                            <li><a href="http://uk.linkedin.com/pub/romain-dumaine/47/92b/159" target="_blank">LINKEDIN</a>        </li>
                            <li><a href="http://vimeo.com/user3039128" target="_blank">VIMEO</a>       </li>
                            <li><a href="http://soundcloud.com/terzai" target="_blank">SOUNDCLOUD</a>       </li>
                      </div>
                      
                </article>
            </li><!-- /slide -->
            <li>
                <article class="slide-article">
                    <div class="slide-details">
                    <h1>Project</h1>
                    <h2>Interactive Glove (Feb-May 2010)</h2>
                     <p>The interactive Glove project was a research based on a new way to create musical expression, through new common electronic components: accelerometers (which  at this time were not used in this direction).</p>

<p> This research had not the purpose to enumerated all possible ways to express music with those components, but to show and develop one possible way. The main idea was to develop a new utilisation of accelerometers and bending sensors, with the intention of enhancing musical creation in live concert but also to create better interaction with the audience.</p>
 
<p>The research had made an empirical study by applying it on an ordinary glove. It was chosen to use hands as support of these components, due to its natural capacity of adaptation, and its easy way to use it as an interaction with its environment; for instance, interaction with music devices or audience, in the case of live concert.</p>

<p>The main reason of this research was due to the interest in electronic music creation in live, specifically electronic music assisted by computer with the idea to remove physical constraint of instrument and only use natural gesture of the hand as a direct way of creation and interaction.</p>

	<li><a href="https://vimeo.com/album/2055799" target="_blank">VIDEOS</a> 
	
                    </div>
                </article>
            </li><!-- /slide -->
            <li>
                <article class="slide-article">
                    <div class="slide-details">
                        <h1>Project</h1>
                        <h2>Dj Kinect Maxx (Sep-May 2011)</h2>

<p>"Because the computer removes you from your body, the body should be strongly engaged. Because the computer's activity takes place on the tiny playing fields of integrated circuits, the encounter with the computer should take place in human-scaled physical space. Because the computer is objective and disinterested, the experience should be intimate." (D.Rokeby, 2000 cited in Plohman A, 2002).</p>

<p>Main goal of Djs in general is to share and enjoy music, through live mixing. Unfortunately, interaction with the public is sometimes restricted to his minimum value. Mainly Djs perform with tools such as turntables and computers or other electronic devices. Those devices could be defined as restrictive; on the way that performer reveal partially his interaction with his interfaces to the audience. For consequence a "poor effect" is created on audience's engagement giving the impress that DJs have a lack of presence or control over their crowd.</p>

<p>This research was focus on gesture recognition which is considerate as a more "natural" way to interact with computer by removing mechanical and restrictive devices such as keyboard or mouse. At the end of 2010, Microsoft released Kinect to the public. This game controller use gesture recognition to interact with games and Xbox 360 interface. The democratisation and success of control based gesture device was due to the new degree of interaction, which provide a better player's engagement of players in game play.</p>
					<li><a href="https://vimeo.com/album/2155343" target="_blank">VIDEOS</a> 
	
                    </div>
                </article>
            </li><!-- /slide -->
               <li>
                <article class="slide-article">
                    <div class="slide-details">
                        <h1>Project</h1>
                        <h2>Story of a Shaped Sound (Dec-May 2012)</h2>
<p>Story of a shaped sound explores the ideas of Pierre Schaeffer to “shape” a recorded sound. This story is explored by manipulating and shaping one recorded sound in real-time through different gestures executed by the performer. The evolution of the sound is represented by different distinct steps of manipulation and localisation of the human body.</p>

<p>This performance allied the Microsoft Kinect a 3-D vision system based on gesture recognition with ambisonics system. The artistic core of this instrument is to shape a sound with the hands of the performer; every speaker has its own role within the instrument. Waveshaping technique was used to “shape” the sound in a simple and effective manner. Waveshaping technique was mapped in such a way that every movements of the performer's body had a direct effect on the waveshaping technique and the sound produced.</p>
<li><a href="https://vimeo.com/50734855" target="_blank">VIDEO</a> 
                    </div>
                </article>
            </li>
                           <li>
                <article class="slide-article">
                    <div class="slide-details">
                        <h1>Project</h1>
                        <h2>Orchard" (Jun-Sep 2012)</h2>
<p>SMD (Koichi Samuels and Romain Dumaine), performing their composition for improvised performance 'Orchard', using their bespoke MAX/MSP, Kinect and TouchOSC system.</p>
<p>'Orchard' explores the relationship between the performer's physical gestures in space and sound diffusion in a 32.2 channel ambisonic environment. 
Through the embodied nature of the interaction between system and performer, the performer is able to grasp sonic material, shape, manipulate and move sound around the ambisonic sphere, through the physicality of the body.</p>
<li><a href="https://vimeo.com/album/2155277" target="_blank">VIDEOS</a> 
                    </div>
                </article>
            </li><!-- /slide -->
        </ul>
    </div>
</section><!-- /slider -->
<script src="js/jquery-latest.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="flexslider/jquery.flexslider-min.js"></script>
<script src="js/jquery.promptu-menu.js"></script>
<script src="js/retina.js"></script>
<script src="js/custom.js"></script>
</body>
</html>